{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nBjgE_4yBzt",
        "outputId": "ce9d3121-c327-4218-e391-1eb01ea1a0f5"
      },
      "id": "9nBjgE_4yBzt",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pickle\n",
        "import re\n",
        "from string import punctuation\n",
        "\n",
        "nlp = spacy.load(\"/content/drive/MyDrive/FINAL FYP/Tags\")\n",
        "stopword = pickle.load(open('/content/drive/MyDrive/FINAL FYP/Tags/stopword.pkl','rb'))\n",
        "decontracted = pickle.load(open('/content/drive/MyDrive/FINAL FYP/Tags/decontracted.pkl','rb'))\n",
        "removeStopword = pickle.load(open('/content/drive/MyDrive/FINAL FYP/Tags/removeStopword.pkl','rb'))\n",
        "tokens = pickle.load(open('/content/drive/MyDrive/FINAL FYP/Tags/tokens.pkl','rb'))\n",
        "\n",
        "def get_token(sentence):\n",
        "    words = []\n",
        "    for word, ner in sentence:\n",
        "        if ner in ['WORK_OF_ART','LAW','PERSON','NORP','FAC','ORG','GPE','LOC','PRODUCT','EVENT']:\n",
        "            if word not in punctuation:\n",
        "                words.append(word)\n",
        "    return words\n",
        "\n",
        "def get_DT(sentence):\n",
        "    words = []\n",
        "    for word, ner in sentence:\n",
        "        if ner in ['DATE','TIME']:\n",
        "            words.append(word)\n",
        "    return words\n",
        "\n",
        "def getdict(sentence):\n",
        "    return {\"entities\": get_token(sentence),\n",
        "            \"dates\": get_DT(sentence)}"
      ],
      "metadata": {
        "id": "Qc3nDmV08fkh"
      },
      "id": "Qc3nDmV08fkh",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c9988d22",
      "metadata": {
        "id": "c9988d22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e413d86d-7fab-4b71-99ca-93ac12485297"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Islam', 'Prophet', 'Muhammad', 'islam', 'Quran']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "tags = tokens('Islam has a breif history and Prophet Muhammad is the founder of islam and Quran is his book', nlp)\n",
        "get_token(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "480633c5",
      "metadata": {
        "id": "480633c5"
      },
      "outputs": [],
      "source": [
        "# class tagGen:    \n",
        "#     def __init__(self, sentence,nlp):\n",
        "#         self.sentence = sentence\n",
        "#         self.nlp=nlp\n",
        "    \n",
        "#     def tokens(self):\n",
        "#         sentence_nlp = self.nlp(self.sentence)\n",
        "#         return [(word.lemma_, word.ent_type_) for word in sentence_nlp if word.ent_type_]\n",
        "    \n",
        "#     def get_token(self):\n",
        "#         from string import punctuation\n",
        "#         words = []\n",
        "#         for word, ner in self.sentence:\n",
        "#             if ner in ['WORK_OF_ART','LAW','PERSON','NORP','FAC','ORG','GPE','LOC','PRODUCT','EVENT']:\n",
        "#                 if word not in punctuation:\n",
        "#                     words.append(word)\n",
        "#         return words\n",
        "\n",
        "#     def get_DT(self):\n",
        "#         words = []\n",
        "#         for word, ner in self.sentence:\n",
        "#             if ner in ['DATE','TIME']:\n",
        "#                 words.append(word)\n",
        "#         return words\n",
        "    \n",
        "#     def getdict(self):\n",
        "#         return {\"entities\": self.get_token(), \n",
        "#                 \"dates\": self.get_DT()}\n",
        "    \n",
        "#     def removeStopword(self):\n",
        "#         from nltk.corpus import stopwords\n",
        "#         stopword = stopwords.words('english')\n",
        "#         sent = ''\n",
        "#         for word in self.sentence.split(' '):\n",
        "#             if word not in stopword:\n",
        "#                 sent += \" \" + word\n",
        "#         return sent\n",
        "    \n",
        "#     def decontracted(self):\n",
        "#         import re\n",
        "#         contractions_dict = {\n",
        "#             'didn\\'t': 'did not',\n",
        "#             'don\\'t': 'do not',\n",
        "#             'I\\'m': 'I am',\n",
        "#         }\n",
        "#         contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "#         def replace(match):\n",
        "#             return contractions_dict[match.group(0)]\n",
        "#         return contractions_re.sub(replace, self.sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def tokens(sentence, nlp):\n",
        "#     sentence_nlp = nlp(sentence)\n",
        "#     return [(word.lemma_, word.ent_type_) for word in sentence_nlp if word.ent_type_]\n",
        "\n",
        "# def removeStopword(sentence):\n",
        "#     sent = ''\n",
        "#     for word in sentence.split(' '):\n",
        "#         if word not in stopword:\n",
        "#             sent += \" \" + word\n",
        "#     return sent\n",
        "\n",
        "# def decontracted(sentence):\n",
        "#     contractions_dict = {\n",
        "#         'didn\\'t': 'did not',\n",
        "#         'don\\'t': 'do not',\n",
        "#         'I\\'m': 'I am',\n",
        "#     }\n",
        "#     contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "#     def replace(match):\n",
        "#         return contractions_dict[match.group(0)]\n",
        "#     return contractions_re.sub(replace, sentence)"
      ],
      "metadata": {
        "id": "PJA489eE7dWL"
      },
      "id": "PJA489eE7dWL",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(decontracted,open('/content/drive/MyDrive/FINAL FYP/Tags/decontracted.pkl','wb'))\n",
        "# pickle.dump(removeStopword,open('/content/drive/MyDrive/FINAL FYP/Tags/removeStopword.pkl','wb'))\n",
        "# pickle.dump(getdict,open('/content/drive/MyDrive/FINAL FYP/Tags/getdict.pkl','wb'))\n",
        "# pickle.dump(get_DT,open('/content/drive/MyDrive/FINAL FYP/Tags/get_token.pkl','wb'))\n",
        "# pickle.dump(tokens,open('/content/drive/MyDrive/FINAL FYP/Tags/tokens.pkl','wb'))"
      ],
      "metadata": {
        "id": "f7mH24pD8bxZ"
      },
      "id": "f7mH24pD8bxZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "TagsCreator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}